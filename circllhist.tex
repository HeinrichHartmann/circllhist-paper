\documentclass{article}

\usepackage{arxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\hypersetup{hidelinks = true}
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{minted}

\usepackage[]{algorithm2e}

\usepackage{fancyvrb}
\usepackage{mathtools}
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}

\usepackage{graphicx}
\usepackage{subcaption}

% ENVIRONMENTS
\usepackage{amsthm}
\theoremstyle{plain}
\newtheorem{definition}{Definition}[section]
\newtheorem{lemma}[definition]{Lemma}
\newtheorem{proposition}[definition]{Proposition}
\newtheorem{corollary}[definition]{Corollary}
\newtheorem{example}[definition]{Example}
\theoremstyle{remark}
\newtheorem{remark}[definition]{Remark}

% TEXT-MODE MACROS
\newcommand{\IE}{\mathbb{E}}
\newcommand{\IN}{\mathbb{N}}
\newcommand{\IR}{\mathbb{R}}
\newcommand{\IZ}{\mathbb{Z}}
\newcommand{\union}{\cup}
\newcommand{\Union}{\bigcup}
\newcommand{\code}{\texttt} % for use as \code{test()}
\newcommand{\defn}{\emph} % for use as \defn{...}

% MATH-MODE MACROS
\newcommand{\qtext}[1]{\quad\text{#1}\quad} % for use as \def{...} inside text
\newcommand{\ra}{\rightarrow}
\newcommand{\lra}{\longrightarrow}
\newcommand{\floor}[1]{\lfloor#1\rfloor}
\newcommand{\abs}[1]{|#1|}
\newcommand{\eps}{\epsilon}
\newcommand{\float}{\mathrm{float}}
\newcommand{\interval}[1]{[#1)}


\title{circllhist}

\subtitle{The Circonus Log-Linear Histogram}

\author{
  Heinrich Hartmann \\
  \texttt{heinrich.hartmann@circonus.com} \\
  Circonus \\
  \And
  Theo Schlossnagle \\
  \texttt{theo.schlossnagle@circonus.com} \\
  Circonus
}

\begin{document}

\maketitle

\begin{abstract}
  The circllhist histogram is a simple, fast and memory efficient data structure for capturing
  and processing large number of samples, that is particularly suited for applications in
  IT infrastructure monitoring.

  The circllhist allows arbitrary merging of pre-aggregated data without additional loss of accuracy,
  and the approximation of percentiles with low expected error and a-priori bounded maximal error.

  Open-source implementations are available for C/lua/python/Go/Java/JavaScript.
\end{abstract}

\tableofcontents

\input{part1.tex}

\clearpage
\section{Theory}

\begin{figure}
  \includegraphics[width=\textwidth]{assets/LLBins.png}
  \caption{Construction of the Log-Linear Binning}
  \label{fig:llbins}
\end{figure}

The idea behind the circllhist is illustrated in Figure \ref{fig:llbins}, and quick to explain.
We start with a logarithmic binning of the real axes, that has bins at the powers of ten.
\begin{center}
  \begin{BVerbatim}
    ... 0.01, 0.1, 1, 10, 100, ...
  \end{BVerbatim}
\end{center}
We divide each logarithmic bin into $n=90$ equally spaced segments. In this way the bin boundaries
are preciesly the base-10, precision-2 floating point numbers:
\begin{center}
\begin{BVerbatim}
... 1.0,  1.1,  1.2,  ...   9.9,
     10,   11,   12,  ...    99,
    100,  110,  120,  ...   990, ...
\end{BVerbatim}
\end{center}
Those are the bin boundaries for the circllhist data structure.
When samples are inserted into the circllhist, we retain counts of the number of samples in each bin.
This information allows us to approximate the original location of the inserted samples with a
maximal relative error less than $5\%$.

In this section we develop an abstract theory of histograms to a degree that allows us to
formally define circllhist as a linear refinement of a logarithmic histogram structure,
and derive basic properties and error bounds.

\subsection{Binnings}

\begin{definition}
  Let $D \subset \IR$ be a connected subset of the real axes (e.g. $D=\IR, D=[0,1)$).
  A binning of $D$ is a collection of intervals $Bin[i], i \in I$, that are disjoint and collectively cover the binning domain $D$:
  \begin{align*}
    D = \Union_{i\in I} Bin[i] \qtext{and} Bin[i] \cap Bin[j] = \emptyset \qtext{for} i \neq j.
  \end{align*}
  The map that associates to each $x \in D$ the unique index $i$ so that $x \in Bin[i]$ is called
  binning map and is denoted as $bin(x) = i$.
\end{definition}

\begin{remark}
  The binning map $bin: D \ra I$ determines the binning via $Bin[i] = \{ x \in D \,|\, bin(x) = i \}$.
\end{remark}

\begin{example}
  The linear binning of $\IR$ is given by $I = \IZ$, with
  \begin{align*}
    Bin[i] = [i, i+1)  \qtext{and} bin(x)=\floor{x}
  \end{align*}
\end{example}

\begin{example}
  The length $n$ linear binning of $[0,1)$ is given by $I = \{0, \dots, n-1\}$, with
    \begin{align*}
      Bin^{Lin}_n[i]   = [ \frac{i}{n}, \frac{i+1}{n} )
      \qtext{and}
      bin^{Lin}_n(x) = \floor{x \cdot n}
    \end{align*}
\end{example}

\begin{example}
  The logarithmic binning with basis $b > 0$ of $\IR_{>0}$ is given by $I=\IZ$, with
  \begin{align*}
    Bin^{Log}_b[i] = [b^i, b^{i+1})
    \qtext{and}
    bin^{Log}_b(x)=\floor{\log_b(x)}
  \end{align*}
\end{example}

\begin{definition}\label{ref}
  Given a map $\alpha: I \ra J$, and a binning $(I, Bin)$, we can define a new binning
  $(J, Bin^*)$ by setting:
  \begin{align*}
    Bin^*[j] = \Union_{i, \alpha(i) = j} Bin[i], \qtext{and} bin^*(x) = \alpha(bin(x))
  \end{align*}
  In this situation we call $(J, Bin^*)$ a coarsening of $(I, Bin)$, and $(I, Bin)$ a refinement of $(J, Bin^*)$.
\end{definition}

\begin{definition}
  Given a binning $Bin[i], i\in I$ with half-open bins $Bin[i] = [a_i, b_i)$.
  The length-n linear refinement of $(I, Bin)$, is given by the index set $I \times \{0,\dots, n-1\}$,
  bins
  \begin{align}\label{eq:lref}
    L_nBin[i,j] = [ a_i + \frac{j}{n}(b_i - a_i), a_i + \frac{j+1}{n}(b_i - a_i) )
  \end{align}
\end{definition}

\begin{lemma}
  The binning map of the length-n linear refinement is given by:
  \begin{align}\label{eq:lrefmap}
    L_nbin(x) = ( bin(x), \floor{\frac{x - a_{bin(x)}}{b_{bin(x)} - a_{bin(x)}} \cdot n } ).
  \end{align}
\end{lemma}

\begin{proof}
  We have to show that $x \in L_nBin[ L_nbin(x) ]$ for all $x \in D$.
  Let $(i,j) = L_nbin(x)$.
  Since $i = bin(x)$, we know that $x \in [a_i, b_i)$.
  Now we consider the linear map $\phi(x) = (x-a_i)/(b_i-a_i)$ which maps $Bin[i]$ bijectively to $[0,1)$.
  We have $j = \floor{ n \phi(x) }$ by definition of $L_nbin(x)$.
  To show that $x \in L_nBin[ L_nbin(x) ]$ it suffices to verify
  that $\phi(x) \in \phi(L_nBin[i,j]) = [ \frac{j}{n}, \frac{j+1}{n} )$.
  And indeed,
  \begin{align*}
    \frac{j}{n} = \frac{\floor{ n \phi(x) }}{n} \leq \phi(x) <
    \frac{\floor{ n \phi(x) } + 1 }{n} =  \frac{j+1}{n}.
  \end{align*}
\end{proof}

\begin{lemma}
  The length-n linear refinement of a binning $(I, Bin)$ is a refinement in the sense of Definition \ref{ref}.
  The index map is given by $\alpha(i,j) = i$ for $i \in I$, $j \in \{0,\dots,n-1\}$.
\end{lemma}

\begin{proof}
  We have to show that $\Union_{j} L_nBin[i,j] = Bin[i]$, for all $i \in I$.
  Again we consider the linear bijection $\phi(x) = (x-a_i)/(b_i-a_i)$, which maps $Bin[i]$ to $[0,1)$ and $L_nBin[i,j]$ to $[j/n, (j+1)/n)$.
  Hence it suffices to show that $[j/n, (j+1)/n)$ cover $[0,1)$ for $j=0,\dots,n$ which is evident.
\end{proof}

Now we are in a position to define Log-Linear binnings.

\begin{definition}
  The base $b$, length $n$ log-liner binning of $\IR_{>0}$ is the length-n linear refinement of the base-b Logarithmic binning of $\IR_{>0}$.
\end{definition}

\begin{proposition}\label{prop:ll}
  Let $b,p$ be positive integers. The boundaries of the base $b$, length $n = b^p - b^{p-1}$ log-linear
  binning or $\IR_{>0}$ are precisely the base-p precision-p floating point numbers:
  \begin{align*}
    \float_{b,p}(e, d) = \frac{d}{b^{p-1}} \cdot b^e = d \cdot b^{e-p+1} \qtext{with} e \in \IZ, d \in \{ b^{p-1}, \dots, b^p - 1 \}
  \end{align*}
  The binning map is given by
  \begin{align*}
    LL_{n,b}bin(x) = (e(x), d(x) - b^{p-1}), \qtext{with} e(x) = \floor{\log_b(x)},\; d(x) = \floor{x \cdot b^{-e(x) + p - 1}}
  \end{align*}
  with values $e(x) \in \IZ$ and $d(x) \in \{b^{p-1}, \dots, b^{o} - 1\}$.
  This binning is also called base-b precision-p log-linear binning.
\end{proposition}

\begin{example}
  According to Proposition \ref{prop:ll}, the base-10 precision-1 binning has bin boundaries at
  \begin{align*}
      \{ d \cdot 10^e  \,|\, e \in \IZ, d \in \{ 1, \dots, 9 \} \} = \{ \dots 0.8, 0.9,\; 1, 2 \dots, 8, 9,\; 10, 20 \dots \}
  \end{align*}
  binning map
  \begin{align*}
    LL_{n,b}bin(x) = (e(x), d(x) - 1), \qtext{with} e(x) = \floor{\log_{10}(x)},\; d(x) = \floor{x / 10^{e(x)}}.
  \end{align*}
\end{example}

\begin{proof}
  To proof Proposition \ref{prop:ll}, we compute the log-linear bin boundaries using equation \ref{eq:lref}
  with $a_i = b^i, b_i = b^{i+1}$ and $n = b^p - b^{p-1}$:
  \begin{align*}
    LL_{b,n}Bin[e,j] &= [ b^e + \frac{j}{b^p - b^{p-1}}(b^{e+1} - b^e), b^e + \frac{j + 1}{b^p - b^{p-1}}(b^{e+1} - b^e) ) \\
      &= [ b^{e-p+1}(b^{p-1} + j), b^{e-p+1}(b^{p-1} + j + 1) ) \\
      &= [ d b^{e-p+1}, (d + 1) b^{e-p+1} )
  \end{align*}
  where we set $d = b^{p-1} + j$. If $j$ runs through $1 \dots n$, then $d$ runs through $b^{p-1},\dots, b^p -1$.
  This shows that the lower boundaries are exactly the base-b precision-p floating point numbers.
  For the upper boundary note, that the if $d=b^p-1$ then $(d+1)b^{e-p+1} = b^{p-1} b^{(e+1)-p+1}$ is again
  a base-b precision-p floating point number (with a larger exponent).

  The binning map can be explicitly calculated using Equation \ref{eq:lrefmap} as:
  \begin{align*}
    LL_{b,n}bin(x) &= (e(x), k(x)), \qtext{with} e(x) = \floor{\log_b(x)} \\
    k(x) & = \floor{ \frac{x - b^{e}}{b^{e+1} - b^e} (b^p - b^{p-1}) }
    = \floor{x \cdot b^{-e + p - 1}} - b^{p-1}
    = d(x) - b^{p-1}
  \end{align*}
  as claimed.
\end{proof}

\begin{definition}
  The circllhist binning is the base-10 precision-2 log-linear binning extended to the real axes,
  with bins:
  \begin{align*}
    CLLBin[+1,e,d] &= [ d \cdot {10}^{e-1}, (d + 1) 10^{e-1} ), \quad e \in \IZ, d \in \{ 10, \dots, 99 \} \\
    CLLBin[0,0,0]  &= \{ 0 \} \\
    CLLBin[-1,e,d] &= [ -d \cdot {10}^{e-1}, -(d + 1) \cdot 10^{e-1} ).
  \end{align*}
  The binning map is given by:
  \begin{align*}
    CLLbin(x)  &= (+1, e, d), e = \floor{\log_{10}(x)}, d = \floor{x \cdot 10^{-e - 1}} \\
    CLLbin(0)  &= (0, 0, 0) \\
    CLLbin(-x) &= (-1, e, d)
  \end{align*}
  for $x > 0$.
\end{definition}

\begin{proposition} \label{prop:rec}
  The binning map of the circllhist can be recursively computed as follows:

  \begin{figure}[h]
  \begin{cetner}
    \begin{BVerbatim}
  function CLLbin(x)
    if x == 0:
      return (0,0,0)
    if x < 0:
      (s, e, d) := CLLbin(-x)
      return (-1, e, d)
    if x < 10:
      return CLLbin(x * 10) - (0, 1, 0)
    if x > 100:
      return CLLbin(x / 10) + (0, 1, 0)
    else: # 10 <= x < 100:
      return (+1, 1, floor(x))
  end
    \end{BVerbatim}
  \end{cetner}
  \end{figure}

  In particular, the circllhist binning map can be computed without use of the logarithm function.
\end{proposition}

\begin{proof}
  The recursion terminates since every positive number $x$ can be brought into range $10 \leq x <
  100$ with a finite number of divisions or multiplications by $10$.  It's straight forward to
  verify that each case computes valid results assuming that the results of the recursive call are
  correct.
\end{proof}

\begin{remark}
  If $x,e$ are integers, than the binning map of the number $x \cdot 10^{e}$ can be computed without
  the use of floating point arithmetic as $CLLbin(x) + (0,e,0)$ using Algorithm \ref{prop:rec}.

  This is of practical relevance when used in an environment which do not have floating
  point arithmetic available. One example being nano-second latencies measured in the Linux kernel,
  or embedded devices.
\end{remark}

\subsection{Paretro Midpoints}

\begin{proposition} \label{prop:pdist}
  Given an interval $[a,b]$ in $\IR_{>0}$ the unique point $m$ in $[a,b]$ so that the maximal
  relative distance $rd(m, y) = |m-y|/y$ to all other points in $[a,b]$ is minimized
  by the paretro midpoint
  $m = 2ab / (a + b)$.

  The maximal relative distance to the paretro midpoint is is $(b - a) / (a + b)$
\end{proposition}

\begin{proof}
  We have to minimize the function $maxrd(x) = max_{y\in[a,b]} rd(x, y)$ over $[a,b]$.
  The maximum $max_{y\in[a,b]} rd(x, y)$ is attained either for $y = a$ or $y = b$,
  hence $maxrd(x) = max\{ rd(x,a), rd(x,b) \}$.

  Note that the function $f(x) = rd(x, a)$ is continues and strictly monotonically increasing on $[a,b]$, with $f(a) = 0, f(b) > 0$,
  and the function $g(x) = rd(x, b)$ is continues and strictly monotonically decreasing on $[a,b]$, with $g(a) > 0$ and $g(b) = 0$.
  The point $m$ is the unique point in $[a,b]$ where both functions are equal, with
  \begin{align*}
    rd(m, a) = \frac{b - a}{a + b} = rd(m, b)
  \end{align*}
  Now if $a \leq x < m$ then $rd(x, b) = g(x) > g(m)$ and so $maxrd(x) > maxrd(m) = g(m)$.
  Similarly if $m < x \leq b$ then $rd(x, a) = f(x) > f(m)$ and so $maxrd(x) > maxrd(m) = f(m)$.

  This shows that $x=m$ is the unique minimum of $maxrd(x)$ on $[a,b]$.
\end{proof}

The following proposition gives a probabilistic interpretation of the location of relative distance minimizing midpoint.
Recall, that the expected value of a uniformly distributed random variable $X \sim U[a,b]$ is the midpoint $\IE[X] = (a+b)/2$.

\begin{proposition}
  Given an interval $[a,b]$, and an a=2 paretro distributed random variable $X$, then
  \begin{align*}
    \IE[ X \, | \, X \in [a,b] \,] = 2ab / (a + b),
  \end{align*}
\end{proposition}

\begin{proof}
  The paretro distribution has density $p(x) =C \cdot 1/x^{a+1}$, for some positive constant $C$, so for $a=2$ we get
  \begin{align*}
    \IE[ X \, | \, X \in [a,b] \,] = \frac{\int_a^b x p(x) dx}{\int_a^b p(x) dx}
    = \frac{\int_a^b x^{-2}  dx}{\int_a^b x^{-3} dx} = 2 \frac{b^{-1} - a^{-1}}{b^{-2}- a^{-2}}
    = \frac{2}{b^{-1} + a^{-1}}
    = 2 \frac{ab}{a + b}
  \end{align*}
  which proves the claim.
\end{proof}

\begin{prosition}
  The maximal relative distance to the paretro midpoint of a bin in the circllhist binning is $1/21 = 4.76\%$
\end{prosition}

\begin{proof}
  Substituting the bin boundaries into the formula given in Proposition \ref{prop:pdist} we find
  $(b - a)(a + b) = 1/(2d + 1)$ for the bin $CLLBin[e,d], e \in \IZ, d \in \{ 10, \dots, 99 \}$.
  This is minimized for $d = 10$ with a value of $1/21$ as claimed.
\end{proof}

\subsection{Histograms}

\begin{definition}
  A histogram with domain $D \subset \IR$ is a binning $Bin[i],I$, together with a count function $c: I \ra \IN_{0}$.
\end{definition}

\subsection{Histogram Operations}

\subsection{Merging}

\subsection{Percentiles}

\section{Implementation}

\section{Evaluation}

\clearpage
\subsection{Calibration}

\begin{figure}
   \includegraphics[width=\textwidth]{evaluation/images/quantile_comparison.png}
   \includegraphics[width=\textwidth]{evaluation/images/Two_Points_quantile_comparison.png}
   \caption{Percentile functions on two-point dataset}
\end{figure}

\begin{figure}
  \centering
  \input{evaluation/tables/Two_Points_quantiles.tex}
  \caption{Percentile values of the two-point dataset $[10,100]$}
\end{figure}

\clearpage
\subsection{Datasets}

\begin{figure}
   \includegraphics[width=\textwidth]{evaluation/images/Uniform_Distribution_distribution_percentiles.png}
   \includegraphics[width=\textwidth]{evaluation/images/API_Latencies_distribution_percentiles.png}
   \includegraphics[width=\textwidth]{evaluation/images/Simulated_Latencies_distribution_percentiles.png}
   \caption{Datasets}
\end{figure}

\clearpage
\subsection{Size}

\begin{figure*}[t!]
  \includegraphics[width=\textwidth]{evaluation/images/all_size.png}
  \caption{Size Comparison}
\end{figure*}

\begin{figure}
  \centering
  \input{evaluation/tables/all_size.tex}
  \caption{Aggregation sizes in kb}
\end{figure}

\clearpage
\subsection{Performance}

\begin{figure}
  \includegraphics[width=\textwidth]{evaluation/images/Uniform_Distribution_perf.png}
  \includegraphics[width=\textwidth]{evaluation/images/API_Latencies_perf.png}
  \includegraphics[width=\textwidth]{evaluation/images/Simulated_Latencies_perf.png}
  \caption{Performance Comparison}
\end{figure}

Tables in usec

Uniform\\
\input{evaluation/tables/Uniform_Distribution_perf.tex}

API Latencies\\
\input{evaluation/tables/API_Latencies_perf.tex}

Simulated API Latency Data\\
\input{evaluation/tables/Simulated_Latencies_perf.tex}

\clearpage
\subsection{Accuracy}

\begin{figure}
  \includegraphics[width=\textwidth]{evaluation/images/Uniform_Distribution_accuracy.png}
  \includegraphics[width=\textwidth]{evaluation/images/API_Latencies_accuracy.png}
  \includegraphics[width=\textwidth]{evaluation/images/Simulated_Latencies_accuracy.png}
  \caption{Accuracy Comparison}
\end{figure}

\begin{figure}
  Uniform\\
  \input{evaluation/tables/Uniform_Distribution_accuracy.tex}
  API Latencies\\
  \input{evaluation/tables/API_Latencies_accuracy.tex}
  Simulated API Latency Data\\
  \input{evaluation/tables/Simulated_Latencies_accuracy.tex}
\end{figure}

\bibliographystyle{unsrt}
\begin{thebibliography}{1}

\bibitem{tdigest}
T. Dunning and O. Ertl.
\newblock  Computing extremeley accurate quantiles using t-digests.
\newblock \url{https://github.com/tdunning/t-digest}, 2017.

\bibitem{dd}
M. Charles, J.E. Rim, H.K. Lee.
\newblock DDSketch: A fast and fully-mergeable quantile sketch with relative-error guarantees.
\newblock Proceedings of the VLDB Endowment 12.12 (2019): 2195-2205.

\bibitem{hdr}
G. Tene,
\newblock HdrHistogram: A high dynamic range (hdr) histogram
\newblock \url{http://hdrhistogram.org/}, 2012

\bibitem{libcircllhist}
  Circonus,
  \newblock libcircllhist: An implementation of Circonus Log-Linear Histograms
  \newblock \url{https://github.com/circonus-labs/libcircllhist}, 2016

\end{thebibliography}
\end{document}
